{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3faf02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_all import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9009b",
   "metadata": {},
   "source": [
    "## Loading the DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7672ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all the data from Matlab file\n",
    "data=scipy.io.loadmat(f'data/features_matrix.mat')\n",
    "labels= np.squeeze(data['labels'])\n",
    "labels_for_ML = 10**labels\n",
    "Y = pd.DataFrame({'y': labels_for_ML})\n",
    "features = data['features']\n",
    "cycling_conditions = data['cycling_conditions']\n",
    "features_names0 = data['features_names']\n",
    "features_names = [subarray[0] for subarray in features_names0[0]]\n",
    "cycling_conditions_names0 = data['cycling_conditions_names']\n",
    "cycling_conditions_names = [subarray[0] for subarray in cycling_conditions_names0[0]]\n",
    "\n",
    "#Concatenating all features in one big array of dim num_cells x num_features\n",
    "all_features = features[:,:,0]\n",
    "for i in range(1,3):\n",
    "    all_features=np.concatenate((all_features,features[:,:,i]),axis=1)\n",
    "    \n",
    "# Creating features names (handles for features df column and metadata df )\n",
    "classes = ['charge', 'full', 'discharge']\n",
    "all_features_names = [my_class+'_'+s  for my_class in classes for s in features_names]\n",
    "\n",
    "# Creating the Features Dataframes\n",
    "all_features_df = pd.DataFrame(all_features, columns = all_features_names)\n",
    "cycling_conditions_df = pd.DataFrame(cycling_conditions, columns = cycling_conditions_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a2eec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating metadata Dataframe for all features\n",
    "features_metadata_df = pd.DataFrame(index = all_features_names)\n",
    "for name, row in features_metadata_df.iterrows():\n",
    "    features_metadata_df.loc[name,'type']=get_feature_type(name)\n",
    "    features_metadata_df.loc[name,'class']=get_feature_class(name)\n",
    "    features_metadata_df.loc[name,'stream']=get_feature_stream(name)\n",
    "    features_metadata_df.loc[name,'num_cycles_needed']=int(name[name.find('y')+9:name.find('y')+12]) \n",
    "    my_min, my_max = get_min_max_percentile(name)\n",
    "    features_metadata_df.loc[name,'min_percentile']=my_min\n",
    "    features_metadata_df.loc[name,'max_percentile']=my_max\n",
    "    features_metadata_df.loc[name,'Pearson']=abs(pearsonr(all_features_df[name],labels_for_ML)[0])\n",
    "    features_metadata_df.loc[name,'Log_Pearson']=abs(pearsonr(all_features_df[name],labels)[0])\n",
    "    \n",
    "#creating metadata Dataframe for cycling conditions\n",
    "cycling_conditions_metadata_df = pd.DataFrame(data = [0,0,0,0],index=cycling_conditions_names,columns=['class'])\n",
    "for name, row in cycling_conditions_metadata_df.iterrows():\n",
    "    cycling_conditions_metadata_df.loc[name,'Pearson']=abs(pearsonr(cycling_conditions_df[name],labels_for_ML)[0])\n",
    "    cycling_conditions_metadata_df.loc[name,'Log_Pearson']=abs(pearsonr(cycling_conditions_df[name],labels)[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd47928b",
   "metadata": {},
   "source": [
    "## Recovering protocols and exclude protocol of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05632328",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/dic_protocol_to_cell_idx.json\")\n",
    "dic_protocell = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f81784",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for key in dic_protocell.keys():\n",
    "    lengths.append(len(dic_protocell[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4839e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = pd.DataFrame(index = list(dic_protocell.keys()),columns = ['repeats','mean','std'])\n",
    "for name in dic_protocell.keys():\n",
    "    protocols.loc[name,'repeats']=len(dic_protocell[name])\n",
    "    protocols.loc[name,'mean']=round(np.mean(Y.loc[dic_protocell[name]].values))\n",
    "    protocols.loc[name,'std']=round(np.std(Y.loc[dic_protocell[name]].values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d958e7",
   "metadata": {},
   "source": [
    "## Tranferability study: excluding one protocol from training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3914c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "types =['charge','full','discharge']\n",
    "time_regions = [150] #comparing charging, full, and discharging models performance. We want a fair comparison so featurization from 141-150 is preferred\n",
    "\n",
    "#Getting a list of 3xlen(time_regions) datasets, 1 per type and time_region\n",
    "metadata_per_class_per_TR = [features_metadata_df[(features_metadata_df['type']==x)&(features_metadata_df['num_cycles_needed']==y)] for x in types for y in time_regions]  \n",
    "datasets = [all_features_df[meta_x.index.values.tolist()] for meta_x in metadata_per_class_per_TR]\n",
    "\n",
    "#creating handles for which dataset is which:\n",
    "my_dataset_order = np.array([[x,y] for x in types for y in time_regions])\n",
    "my_types = my_dataset_order[:,0]\n",
    "my_time_regions = my_dataset_order[:,1]\n",
    "\n",
    "# Initializing my results DF\n",
    "my_columns = ['train MAPE','val MAPE','test MAPE','train RMSE','val RMSE','test RMSE','train MAE','val MAE','test MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28bc001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_protocols = protocols[protocols['repeats']>=5]\n",
    "protocol = list(long_protocols.index)[1]\n",
    "ruleout_list = dic_protocell[protocol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9046541",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_TTS = 10\n",
    "prot_results = np.empty((nb_TTS,9,0))\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "# for i in range(2):\n",
    "    X=datasets[i]\n",
    "    X_trainval,X_test, Y_trainval,Y_test = ruleout_split(X,Y,ruleout_list)\n",
    "\n",
    "    #Initializing results array\n",
    "    RF_trainvaltest_results =  np.empty((0,9))\n",
    "\n",
    "    #looping over 10 Train Test Splits:\n",
    "    for rdstate in range(nb_TTS):\n",
    "        print(f'the dataset is {i} and the TTS is {rdstate}')\n",
    "    ## Splitting into train (train/val) and test sets\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X_trainval, Y_trainval, test_size = 0.2,random_state = rdstate)\n",
    "\n",
    "        ## Make unified dataframes for train and test\n",
    "        df_train = Y_train.join(X_train)\n",
    "        df_val = Y_val.join(X_val)\n",
    "\n",
    "        Y_col = ['y']\n",
    "        X_col =  X.columns.tolist()\n",
    "    \n",
    "        #finding best RF\n",
    "        opt_model, X_train_scaled, Y_train_scaled, X_scaler, Y_scaler = make_cv_model_object(df_train,\n",
    "                                                 Y_col=Y_col,\n",
    "                                                 X_col=X_col,\n",
    "                                                cv_splits = 10,                                       \n",
    "                #                                  split_lists=split_lists,\n",
    "                                                 model=RandomForestRegressor(random_state=0),\n",
    "                                                 model_hyperparams={'n_estimators': [40,80,160],\n",
    "                                                                    'min_samples_leaf':[2,4],#[1,2,4,8]\n",
    "                                                                    'min_samples_split':[2,4,8]})\n",
    "\n",
    "        #Best RF:\n",
    "        best_RF= opt_model.best_estimator_\n",
    "        best_RF.fit(X_train_scaled,Y_train_scaled.values.ravel())\n",
    "\n",
    "        RF_trainval_iter= plot_train_test_model_predictions(best_RF,\n",
    "                                              X_train_scaled = X_train_scaled, X_test = X_val, X_scaler = X_scaler, \n",
    "                                             Y_train = Y_train, Y_test = Y_val, Y_scaler = Y_scaler,\n",
    "                                                X_col=X_col,Y_col=['y'],\n",
    "                                             plot_bounds = [0,2000], plot=False)[0:6]\n",
    "\n",
    "        RF_trainval_iter= np.array(RF_trainval_iter).reshape((1,-1))\n",
    "\n",
    "        #We now look into how the model performs on ruled-out cells, aka Test set:\n",
    "        #to plot parity plot only once per dataset, we print only during the first TTS.\n",
    "        if rdstate ==0:\n",
    "            myFalse = False #set to True to plot parity plot \n",
    "        else: \n",
    "            myFalse= False\n",
    "        _,RF_test_MAPE,_,RF_test_RMSE,_,RF_test_MAE = plot_train_test_model_predictions(best_RF,\n",
    "                                          X_train_scaled = X_train_scaled, X_test = X_test, X_scaler = X_scaler, \n",
    "                                         Y_train = Y_train, Y_test = Y_test, Y_scaler = Y_scaler,\n",
    "                                            X_col=X_col,Y_col=['y'],\n",
    "                                         plot_bounds = [0,2000], plot=myFalse)[0:6]\n",
    "\n",
    "        #Finally, we concatenate the train, val, test errors and add them to our results df\n",
    "        RF_trainvaltest_iter=np.insert(RF_trainval_iter,[2,4,6], [RF_test_MAPE,RF_test_RMSE,RF_test_MAE]).reshape((1,-1))\n",
    "        RF_trainvaltest_results = np.append(RF_trainvaltest_results,RF_trainvaltest_iter,axis=0)\n",
    "    RF_trainvaltest_results = np.expand_dims(RF_trainvaltest_results,axis=-1) #of shape (nb_TTS,9,1)\n",
    "    prot_results = np.append(prot_results,RF_trainvaltest_results,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "458939e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting means and std for one protocol\n",
    "prot_means = np.mean(prot_results,axis =0)\n",
    "prot_std = np.std(prot_results,axis=0)\n",
    "prot_means= prot_means.T\n",
    "prot_std = prot_std.T\n",
    "\n",
    "#Function to build digestible dataFrames\n",
    "def construct_df (array,my_columns,my_types):\n",
    "    df = pd.DataFrame(array,columns=my_columns)\n",
    "    df['type']=my_types\n",
    "    return df\n",
    "\n",
    "# Constructing digestible dataFrame\n",
    "my_columns = ['train MAPE','val MAPE','test MAPE','train RMSE','val RMSE','test RMSE','train MAE','val MAE','test MAE']\n",
    "prot_means_df = construct_df(prot_means,my_columns,types)\n",
    "prot_std_df = construct_df(prot_std,my_columns,types)\n",
    "prot_means_df= prot_means_df.drop(index =1)\n",
    "prot_std_df = prot_std_df.drop(index =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7268c9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac17af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f50eacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b9709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
