{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22000fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install for structure\n",
    "from util_all import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea67c81",
   "metadata": {},
   "source": [
    "## Loading the DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f614d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all the data from Matlab file\n",
    "data=scipy.io.loadmat(f'data/features_matrix.mat')\n",
    "labels= np.squeeze(data['labels'])\n",
    "labels_for_ML = 10**labels\n",
    "Y = pd.DataFrame({'y': labels_for_ML})\n",
    "features = data['features']\n",
    "cycling_conditions = data['cycling_conditions']\n",
    "features_names0 = data['features_names']\n",
    "features_names = [subarray[0] for subarray in features_names0[0]]\n",
    "cycling_conditions_names0 = data['cycling_conditions_names']\n",
    "cycling_conditions_names = [subarray[0] for subarray in cycling_conditions_names0[0]]\n",
    "\n",
    "#Concatenating all features in one big array of dim num_cells x num_features\n",
    "all_features = features[:,:,0]\n",
    "for i in range(1,3):\n",
    "    all_features=np.concatenate((all_features,features[:,:,i]),axis=1)\n",
    "    \n",
    "# Creating features names (handles for features df column and metadata df )\n",
    "classes = ['charge', 'full', 'discharge']\n",
    "all_features_names = [my_class+'_'+s  for my_class in classes for s in features_names]\n",
    "\n",
    "# Creating the Features Dataframes\n",
    "all_features_df = pd.DataFrame(all_features, columns = all_features_names)\n",
    "cycling_conditions_df = pd.DataFrame(cycling_conditions, columns = cycling_conditions_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4fb673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating metadata Dataframe for all features\n",
    "features_metadata_df = pd.DataFrame(index = all_features_names)\n",
    "for name, row in features_metadata_df.iterrows():\n",
    "    features_metadata_df.loc[name,'type']=get_feature_type(name)\n",
    "    features_metadata_df.loc[name,'class']=get_feature_class(name)\n",
    "    features_metadata_df.loc[name,'stream']=get_feature_stream(name)\n",
    "    features_metadata_df.loc[name,'num_cycles_needed']=int(name[name.find('y')+9:name.find('y')+12]) \n",
    "    my_min, my_max = get_min_max_percentile(name)\n",
    "    features_metadata_df.loc[name,'min_percentile']=my_min\n",
    "    features_metadata_df.loc[name,'max_percentile']=my_max\n",
    "    features_metadata_df.loc[name,'Pearson']=abs(pearsonr(all_features_df[name],labels_for_ML)[0])\n",
    "    features_metadata_df.loc[name,'Log_Pearson']=abs(pearsonr(all_features_df[name],labels)[0])\n",
    "    \n",
    "#creating metadata Dataframe for cycling conditions\n",
    "cycling_conditions_metadata_df = pd.DataFrame(data = [0,0,0,0],index=cycling_conditions_names,columns=['class'])\n",
    "for name, row in cycling_conditions_metadata_df.iterrows():\n",
    "    cycling_conditions_metadata_df.loc[name,'Pearson']=abs(pearsonr(cycling_conditions_df[name],labels_for_ML)[0])\n",
    "    cycling_conditions_metadata_df.loc[name,'Log_Pearson']=abs(pearsonr(cycling_conditions_df[name],labels)[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a123f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deede828",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5d43f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(all_features_df, features_metadata_df, dataset_type):\n",
    "    time_regions = [1,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150]\n",
    "\n",
    "    #Getting a list of x datasets, 1 per time_region (TR)\n",
    "    metadata_per_TR = [features_metadata_df[(features_metadata_df['num_cycles_needed']==y)&(features_metadata_df['type']==dataset_type)] for y in time_regions]  \n",
    "    datasets = [all_features_df[meta_x.index.values.tolist()] for meta_x in metadata_per_TR]\n",
    "    return  datasets, metadata_per_TR\n",
    "\n",
    "charge_datasets, charge_meta = get_datasets(all_features_df, features_metadata_df, \"charge\")\n",
    "discharge_datasets, discharge_meta = get_datasets(all_features_df, features_metadata_df, \"discharge\")\n",
    "full_datasets, full_meta = get_datasets(all_features_df, features_metadata_df, \"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b4719",
   "metadata": {},
   "source": [
    "## Use Single Discharge Features to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaca4ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = pd.DataFrame({'y': labels_for_ML})\n",
    "\n",
    "performance_by_split = []\n",
    "for TTS in range(10):\n",
    "    discharge_mapes = []\n",
    "    for j, Z in enumerate(discharge_datasets):\n",
    "        discharge_mapes.append([])\n",
    "        feature_order = []\n",
    "        for i, X in Z.iteritems():\n",
    "            print(f\"------{TTS, j, i}--------\")\n",
    "            feature_order.append(i)\n",
    "            X = pd.DataFrame(X)\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=TTS)\n",
    "\n",
    "            ## Make unified dataframes for train and test\n",
    "            df_train = Y_train.join(X_train)\n",
    "            df_test = Y_test.join(X_test)\n",
    "\n",
    "            Y_col = ['y']\n",
    "            X_col =  X.columns.tolist()\n",
    "\n",
    "            #finding best RF\n",
    "            opt_model, X_train_scaled, Y_train_scaled, X_scaler, Y_scaler = make_cv_model_object(df_train,\n",
    "                                                     Y_col=Y_col,\n",
    "                                                     X_col=X_col,\n",
    "                                                    cv_splits = 10,                                       \n",
    "                                                     model=RandomForestRegressor(random_state=0),\n",
    "                                                     model_hyperparams={'n_estimators': [40,80,160],\n",
    "                                                                        'min_samples_leaf':[2,4],#[1,2,4,8]\n",
    "                                                                        'min_samples_split':[2,4,8]})\n",
    "\n",
    "            #Best RF:\n",
    "            best_RF= opt_model.best_estimator_\n",
    "            best_RF.fit(X_train_scaled,Y_train_scaled.values.ravel())\n",
    "\n",
    "            RF_iter_result= plot_train_test_model_predictions(best_RF,\n",
    "                                                  X_train_scaled = X_train_scaled, X_test = X_test, X_scaler = X_scaler, \n",
    "                                                 Y_train = Y_train, Y_test = Y_test, Y_scaler = Y_scaler,\n",
    "                                                    X_col=X_col,Y_col=['y'],\n",
    "                                                 plot_bounds = [0,2000], plot=False)[0:6]\n",
    "\n",
    "            discharge_mapes[-1].append(RF_iter_result[1])\n",
    "    performance_by_split.append(discharge_mapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c31751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_discharge_fit(discharge_mapes):\n",
    "    dis_p = pd.DataFrame(discharge_mapes).T   \n",
    "    dis_p = dis_p.reindex(dis_p.mean(axis=1).sort_values().index) #sorting dataframe by features, according to average MAPE across 16 time regions (increasingly).\n",
    "    dis_p.index = discharge_meta[0].index[dis_p.index]  # placing the features names as the index\n",
    "    return dis_p    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d1f33c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_discharges = []\n",
    "for i in range(10):\n",
    "    average_discharges.append(plot_discharge_fit(performance_by_split[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abbc8b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from all the results stored in average_discharge (1 dataframe per TTS), we recover the average and std MAPEs across all TTS.\n",
    "index = average_discharges[0].index\n",
    "feature_averages = []\n",
    "feature_stds =[]\n",
    "for feature in index:\n",
    "    feature_df = [] #our list to store all values across the 10 TTS, for each feature\n",
    "    for TTS in range(10):\n",
    "        feature_df.append(average_discharges[TTS].loc[feature])\n",
    "    x = pd.DataFrame(feature_df).mean(axis=0)\n",
    "    x.name = feature\n",
    "    feature_averages.append(x)\n",
    "    z= pd.DataFrame(feature_df).std(axis=0)\n",
    "    z.name = feature\n",
    "    feature_stds.append(z)\n",
    "\n",
    "feature_averages = pd.DataFrame(feature_averages)\n",
    "feature_stds = pd.DataFrame(feature_stds)\n",
    "\n",
    "#creating a dict mapping to rename the columns of the dataframes with the time_regions\n",
    "feature_stds.columns.tolist()\n",
    "time_regions = [1,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150]\n",
    "renaming = dict(zip(feature_stds.columns.tolist(),time_regions))\n",
    "\n",
    "#renaming\n",
    "feature_stds= feature_stds.rename(columns=renaming)\n",
    "feature_averages = feature_averages.rename(columns=renaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704f1db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
