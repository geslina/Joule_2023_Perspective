{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "523650de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install for structure\n",
    "from util_all import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54def5e5",
   "metadata": {},
   "source": [
    "## Loading the DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30f0cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all the data from Matlab file\n",
    "data=scipy.io.loadmat(f'data/features_matrix.mat')\n",
    "labels= np.squeeze(data['labels'])\n",
    "labels_for_ML = 10**labels\n",
    "Y = pd.DataFrame({'y': labels_for_ML})\n",
    "features = data['features']\n",
    "cycling_conditions = data['cycling_conditions']\n",
    "features_names0 = data['features_names']\n",
    "features_names = [subarray[0] for subarray in features_names0[0]]\n",
    "cycling_conditions_names0 = data['cycling_conditions_names']\n",
    "cycling_conditions_names = [subarray[0] for subarray in cycling_conditions_names0[0]]\n",
    "\n",
    "#Concatenating all features in one big array of dim num_cells x num_features\n",
    "all_features = features[:,:,0]\n",
    "for i in range(1,3):\n",
    "    all_features=np.concatenate((all_features,features[:,:,i]),axis=1)\n",
    "    \n",
    "# Creating features names (handles for features df column and metadata df )\n",
    "classes = ['charge', 'full', 'discharge']\n",
    "all_features_names = [my_class+'_'+s  for my_class in classes for s in features_names]\n",
    "\n",
    "# Creating the Features Dataframes\n",
    "all_features_df = pd.DataFrame(all_features, columns = all_features_names)\n",
    "cycling_conditions_df = pd.DataFrame(cycling_conditions, columns = cycling_conditions_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d98cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating metadata Dataframe for all features\n",
    "features_metadata_df = pd.DataFrame(index = all_features_names)\n",
    "for name, row in features_metadata_df.iterrows():\n",
    "    features_metadata_df.loc[name,'type']=get_feature_type(name)\n",
    "    features_metadata_df.loc[name,'class']=get_feature_class(name)\n",
    "    features_metadata_df.loc[name,'stream']=get_feature_stream(name)\n",
    "    features_metadata_df.loc[name,'num_cycles_needed']=int(name[name.find('y')+9:name.find('y')+12]) \n",
    "    my_min, my_max = get_min_max_percentile(name)\n",
    "    features_metadata_df.loc[name,'min_percentile']=my_min\n",
    "    features_metadata_df.loc[name,'max_percentile']=my_max\n",
    "    features_metadata_df.loc[name,'Pearson']=abs(pearsonr(all_features_df[name],labels_for_ML)[0])\n",
    "    features_metadata_df.loc[name,'Log_Pearson']=abs(pearsonr(all_features_df[name],labels)[0])\n",
    "    \n",
    "#creating metadata Dataframe for cycling conditions\n",
    "cycling_conditions_metadata_df = pd.DataFrame(data = [0,0,0,0],index=cycling_conditions_names,columns=['class'])\n",
    "for name, row in cycling_conditions_metadata_df.iterrows():\n",
    "    cycling_conditions_metadata_df.loc[name,'Pearson']=abs(pearsonr(cycling_conditions_df[name],labels_for_ML)[0])\n",
    "    cycling_conditions_metadata_df.loc[name,'Log_Pearson']=abs(pearsonr(cycling_conditions_df[name],labels)[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac112f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05c9c82a",
   "metadata": {},
   "source": [
    "## Dummy Model benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c347be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= cycling_conditions_df\n",
    "dummy_results = np.empty((0,6))\n",
    "for TTS in range(10):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=TTS)\n",
    "    dummy_model = DummyRegressor() # default is average\n",
    "    dummy_model.fit(X_train, Y_train)\n",
    "    train_predictions = dummy_model.predict(X_train)\n",
    "    predictions = dummy_model.predict(X_test)\n",
    "    dummy_iter_result = plot_n_MAPE_TTS (np.array(Y_train), train_predictions,np.array(Y_test), predictions,plot=False) \n",
    "    dummy_iter_result= np.array(dummy_iter_result).reshape((1,-1))\n",
    "    dummy_results = np.append(dummy_results,dummy_iter_result,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e16fc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train MAPE      0.4038\n",
       "test MAPE       0.4120\n",
       "train RMSE    370.4056\n",
       "test RMSE     403.9809\n",
       "train MAE     270.9863\n",
       "test MAE      298.3506\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_columns = ['train MAPE','test MAPE','train RMSE','test RMSE','train MAE','test MAE']\n",
    "dummy_results_df = pd.DataFrame(dummy_results,columns=my_columns)\n",
    "dummy_results_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0210dc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train MAPE     0.013298\n",
       "test MAPE      0.073740\n",
       "train RMSE    19.976498\n",
       "test RMSE     68.829514\n",
       "train MAE     12.761092\n",
       "test MAE      43.724007\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_results_df.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4631ab90",
   "metadata": {},
   "source": [
    "## Class 0 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c01c7b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing iteration TTS 0 ---------------\n",
      "doing iteration TTS 1 ---------------\n",
      "doing iteration TTS 2 ---------------\n",
      "doing iteration TTS 3 ---------------\n",
      "doing iteration TTS 4 ---------------\n",
      "doing iteration TTS 5 ---------------\n",
      "doing iteration TTS 6 ---------------\n",
      "doing iteration TTS 7 ---------------\n",
      "doing iteration TTS 8 ---------------\n",
      "doing iteration TTS 9 ---------------\n"
     ]
    }
   ],
   "source": [
    "#Data selection and preparation\n",
    "X= cycling_conditions_df\n",
    "class0_ENet_results = np.empty((0,6))\n",
    "class0_RF_results = np.empty((0,6))\n",
    "for TTS in range(10):\n",
    "    print(f'doing iteration TTS {TTS} ---------------')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=TTS)\n",
    "    df_train = Y_train.join(X_train)\n",
    "    df_test = Y_test.join(X_test)\n",
    "\n",
    "    Y_col = ['y']\n",
    "    X_col =  X.columns.tolist()\n",
    "    \n",
    "    #finding best ENet\n",
    "    warnings.simplefilter('ignore')\n",
    "    opt_model, X_train_scaled, Y_train_scaled, X_scaler, Y_scaler = make_cv_model_object(df_train,\n",
    "                                     X_col=X_col,Y_col=Y_col,\n",
    "                                    cv_splits = 10,                                       \n",
    "    #                                  split_lists=split_lists,\n",
    "                                     model=ElasticNet(random_state=25),\n",
    "                                     model_hyperparams={'alpha': [0.00001, 0.00005,0.0001,0.001,0.005,0.01,0.02,0.03,0.04,0.1],\n",
    "                                                        'l1_ratio':[0.2,0.3,0.4,0.5,0.6,0.7,0.8]})\n",
    "\n",
    "    #Recover best ENet and train it on the totality of X_train:\n",
    "    best_ENet= opt_model.best_estimator_\n",
    "    best_ENet.fit(X_train_scaled,Y_train_scaled.values.ravel())\n",
    "\n",
    "    ENet_iter_result = plot_train_test_model_predictions(best_ENet,\n",
    "                                          X_train_scaled = X_train_scaled, X_test = X_test, X_scaler = X_scaler, \n",
    "                                         Y_train = Y_train, Y_test = Y_test, Y_scaler = Y_scaler,\n",
    "                                            X_col=X_col,Y_col=['y'],\n",
    "                                         plot_bounds = [0,2000], plot=False)[0:6]\n",
    "\n",
    "    ENet_iter_result = np.array(ENet_iter_result).reshape((1,-1))\n",
    "    class0_ENet_results = np.append(class0_ENet_results,ENet_iter_result,axis=0)\n",
    "\n",
    "    #finding best RF\n",
    "    opt_model, X_train_scaled, Y_train_scaled, X_scaler, Y_scaler = make_cv_model_object(df_train,\n",
    "                                             Y_col=Y_col,\n",
    "                                             X_col=X_col,\n",
    "                                            cv_splits = 10,                                       \n",
    "            #                                  split_lists=split_lists,\n",
    "                                             model=RandomForestRegressor(random_state=0),\n",
    "                                             model_hyperparams={'n_estimators': [40,80,160],\n",
    "                                                                'min_samples_leaf':[2,4],#[1,2,4,8]\n",
    "                                                                'min_samples_split':[2,4,8]})\n",
    "\n",
    "    #Best RF:\n",
    "    best_RF= opt_model.best_estimator_\n",
    "    best_RF.fit(X_train_scaled,Y_train_scaled.values.ravel())\n",
    "\n",
    "    RF_iter_result= plot_train_test_model_predictions(best_RF,\n",
    "                                          X_train_scaled = X_train_scaled, X_test = X_test, X_scaler = X_scaler, \n",
    "                                         Y_train = Y_train, Y_test = Y_test, Y_scaler = Y_scaler,\n",
    "                                            X_col=X_col,Y_col=['y'],\n",
    "                                         plot_bounds = [0,2000], plot=False)[0:6]\n",
    "\n",
    "    RF_iter_result= np.array(RF_iter_result).reshape((1,-1))\n",
    "    class0_RF_results = np.append(class0_RF_results,RF_iter_result,axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1eb35e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAPE      0.296472\n",
      "test MAPE       0.296754\n",
      "train RMSE    273.817342\n",
      "test RMSE     299.486306\n",
      "train MAE     206.078215\n",
      "test MAE      221.547571\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train MAPE      0.168508\n",
       "test MAPE       0.264454\n",
       "train RMSE    200.047991\n",
       "test RMSE     280.175617\n",
       "train MAE     125.051852\n",
       "test MAE      194.440774\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_columns = ['train MAPE','test MAPE','train RMSE','test RMSE','train MAE','test MAE']\n",
    "class0_ENet_results_df = pd.DataFrame(class0_ENet_results,columns=my_columns)\n",
    "class0_RF_results_df = pd.DataFrame(class0_RF_results,columns=my_columns)\n",
    "print(class0_ENet_results_df.mean(axis=0))\n",
    "class0_RF_results_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57268ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAPE     0.012088\n",
      "test MAPE      0.043983\n",
      "train RMSE     8.456005\n",
      "test RMSE     39.205220\n",
      "train MAE      7.698141\n",
      "test MAE      32.613813\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train MAPE     0.014638\n",
       "test MAPE      0.042548\n",
       "train RMSE    14.612636\n",
       "test RMSE     39.145225\n",
       "train MAE     10.928223\n",
       "test MAE      28.373068\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(class0_ENet_results_df.std(axis=0))\n",
    "class0_RF_results_df.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac80663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99b2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
